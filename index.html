<html>
<head>
<title>LaTeX4Web 1.4 OUTPUT</title>
<style type="text/css">
<!--
 body {color: black;  background:"#FFCC99";  }
 div.p { margin-top: 7pt;}
 td div.comp { margin-top: -0.6ex; margin-bottom: -1ex;}
 td div.comb { margin-top: -0.6ex; margin-bottom: -.6ex;}
 td div.norm {line-height:normal;}
 td div.hrcomp { line-height: 0.9; margin-top: -0.8ex; margin-bottom: -1ex;}
 td.sqrt {border-top:2 solid black;
          border-left:2 solid black;
          border-bottom:none;
          border-right:none;}
 table.sqrt {border-top:2 solid black;
             border-left:2 solid black;
             border-bottom:none;
             border-right:none;}
-->
</style>
</head>
<body>
\documentclassarticle
\usepackageamsmath
\usepackage[a4paper]geometry
\usepackageamssymb
\usepackagehyperref
\usepackage[utf8]inputenc
\usepackagegraphicx
<font face=symbol>Â</font>newcommand <font face=symbol>£</font>  <font face=symbol>£</font> slant
<font face=symbol>Â</font>newcommand <font face=symbol>³</font>  <font face=symbol>³</font> slant
\newcommand\exclu\mathrmmls
\newcommand <font face=symbol>Î</font> clu<span style="border-top:1 solid black;">\exclu</span>

\titleBaltic Olympiad In Informatics 2018 Day 1<br>
 Solutions
\date\vspace-5ex

\begindocument

\maketitle

<h1>Love Polygon <font face=symbol>©</font></h1>
In essence, we have a directed graph where each vertex has exactly one outgoing
arc. We are asked to redirect some of the arcs so that each vertex is in a ``pair<font face=symbol>¢</font><font face=symbol>¢</font>
and we are asked to do it with the minimum number of redirects. This type of graph,
called a ``functional graph<font face=symbol>¢</font><font face=symbol>¢</font>, inevitably takes the form where each connected component
is a directed cycle with directed trees branching off of it.

Note that some sort of solution is always possible if N is even, and always impossible
if N is odd. Therefore, if N is odd we can immediately output \verb!-1!. The following
explanations deal with the case where N is even.

<h2>Subtask 1</h2>
Let G be the set of all people; let S be a subset of G and let T = G \setminus S.
In order for S to be the set of people <font face=symbol>©</font>-shot in any solution, the following conditions
must hold:
<ul>

<li> If we remove the edges originating from people in S, all connected components
  in the resulting graph must have at most 2 vertices. This is because the final graph
  can be constructed by only adding edges to this graph, and in the final graph all connected
  components have 2 vertices.

<li> No person who loves themselves can be in T, because then they will love themselves
  in the final arrangement, which is not permitted.
</ul>
If these conditions hold, S can be used to construct a solution by pairing off the people
in connected components of size 2 and pairing everyone else off randomly. |S| arrows will
be used. Therefore, a set S can be the set of people shot if and only if those conditions are met.

To solve the problem, we can iterate over all sets S and check for this property, then pick
the smallest fitting set S<sup>*</sup> and output |S<sup>*</sup>|. There are 2<sup>N</sup> subsets of G, checking each
set can be done in \mathcalO(N) time. The complexity is therefore \mathcalO(N 2<sup>N</sup>).

An alternative approach is to use dynamic programming on subsets in \mathcalO(N 2<sup>N</sup>) time.

<h2>Subtask 2</h2>
In order for everyone to be loved by someone, everyone must be loved by exactly one person.
In this subtask, each connected component of the graph takes the form of a cycle.
Let<font face=symbol>¢</font>s process each component separately, let C be the number of vertices in the
component. It is easy to see that if the component has
an even number of vertices, then it is optimal to pair each vertex off with one of its
neighbours, using (C)/(2) arrows, unless the component has 2 vertices, in which case
no arrows are needed. On the other hand, if the component has an odd
number of vertices, then it is optimal to pair each vertex but one off with one of
its neighbours, pairing the last vertex off with a vertex outside of that component,
using lfloor (C)/(2) <td>
  rfloor + 1 arrows. The problem can be solved in
\mathcalO(N) time by counting the vertices in each component.

<h2>Subtask 3</h2>
Since there are no ``love polygon<font face=symbol>¢</font><font face=symbol>¢</font>, that must mean the cycle in each connected component
of the graph consists of one character loving themselves. This means each connected
component takes the form of a directed tree with all edges directed towards the root.

We call a set of vertices T in the forest \emphlucky if and only if:
<ul>

<li> For each vertex in T, its parent is not in T;

<li> For each vertex in T, none of its children are in T;

<li> For each vertex in T, none of its siblings are in T.
</ul>
Let S<sup>*</sup> be the set of vertices that are not shot with a love arrow in the optimal solution.
Then S<sup>*</sup> is clearly a lucky set: any character in that set will end up in a relationship with
the character they initially loved; that is, they will be paired off with their parent
in the tree. Let v be in S<sup>*</sup>, then:
<ul>

<li> The parent of v must be shot with an arrow to love v. Therefore the parent of v is
  not in S<sup>*</sup>.

<li> All children of v must be shot with an arrow, otherwise they would end up in a
  pair with v, but we know v will be paired off with its parent. Therefore no children of
  v are in S<sup>*</sup>.

<li> All siblings of v must be shot with an arrow, otherwise they would end up in a
  pair with the parent of v, but we know the parent of v will be paired off with v.
  Therefore no siblings of v are in S<sup>*</sup>.
</ul>
Hence, S<sup>*</sup> is a lucky set. Note that the number of love arrows required is N <font face=symbol>-</font> |S<sup>*</sup>|.
Furthermore, given any lucky set S that doesn<font face=symbol>¢</font>t contain roots, we can construct a solution
using N <font face=symbol>-</font> |S| arrows by pairing the vertices in S off with their parents and pairing
everyone else off randomly. Therefore, if we define R as the set of lucky sets that don<font face=symbol>¢</font>t
contain roots, the solution to the problem is

<table cellspacing=0  border=0 align=center>
<tr>
  <td nowrap align="center">
    
  \min<sub>S  <font face=symbol>Î</font>  R</sub> 
  </td>
  <td style="border-left:1 solid black;border-top:1 solid black;border-bottom:1 solid black;">&nbsp;
  </td>
  <td>
     N <font face=symbol>-</font> |S| 
  </td>
  <td style="border-right:1 solid black;border-top:1 solid black;border-bottom:1 solid black;">&nbsp;
  </td>
  <td>
     = N <font face=symbol>-</font> \max<sub>S  <font face=symbol>Î</font>  R</sub> |S|.
<a name="eq0">&nbsp;&nbsp;&nbsp;&nbsp;<font color=blue>(0)</font>
  </td>
</tr>
</table>

Our task is therefore to calculate the size of the largest lucky set that doesn<font face=symbol>¢</font>t contain
any roots. This can be done using dynamic programming.

Let L<sub>v</sub> denote the set of initial lovers (children) of vertex v, excluding vertex v
itself if v is a root. Define:
<ul>

<li> \exclu(v) to be the size of the maximum lucky set within the subtree of v whose
  member v itself is not.

<li>  <font face=symbol>Î</font> clu(v) to be the size of the maximum lucky set within the subtree of v whose
  member v itself is.
</ul>
The size of the largest lucky set is then <font face=symbol>å</font> \exclu(r) over all roots r. If vertex
v is a leaf, then clearly \exclu(v) = 0 and  <font face=symbol>Î</font> clu(v) = 1. Let v be a nonleaf vertex.
Then the equation

<table cellspacing=0  border=0 align=center>
<tr>
  <td nowrap align="center">
    
   <font face=symbol>Î</font> clu(v) = 1 + 
  </td>
  <td nowrap align=center>
    <!--UB--><font face=symbol>å</font><sub>u  <font face=symbol>Î</font>  L<sub>v</sub></sub> \exclu(u)
<a name="eq1">&nbsp;&nbsp;&nbsp;&nbsp;<font color=blue>(1)</font>
  </td>
</tr>
</table>

clearly holds. Lucky sets within the subtree of v that don<font face=symbol>¢</font>t contain the vertex v
can either:
<ul>

<li> Not contain any of the children of v. The largest of them has size
  <font face=symbol>å</font><sub>u  <font face=symbol>Î</font>  L<sub>v</sub></sub> \exclu(u).

<li> Contain exactly one of the children of v. The largest lucky set containing w,
  a child of v, has size 
</td>
<td style="border-left:1 solid black;border-top:1 solid black;border-bottom:1 solid black;">&nbsp;
</td>
<td>
   <font face=symbol>å</font><sub>u  <font face=symbol>Î</font>  L<sub>v</sub></sub> \exclu(u) 
</td>
<td style="border-right:1 solid black;border-top:1 solid black;border-bottom:1 solid black;">&nbsp;
</td>
<td>
   +  <font face=symbol>Î</font> clu(w) <font face=symbol>-</font> \exclu(w).
</ul>
All those kinds of lucky sets exist, the largest of them has therefore size
\beginalign*
  & \max  <font face=symbol>å</font>_u  <font face=symbol>Î</font>  L_v \exclu(u), &nbsp;&nbsp;&nbsp; \max_w  <font face=symbol>Î</font>  L_v
  
</td>
<td style="border-left:1 solid black;border-top:1 solid black;border-bottom:1 solid black;">&nbsp;
</td>
<td>
   
</td>
<td style="border-left:1 solid black;border-top:1 solid black;border-bottom:1 solid black;">&nbsp;
</td>
<td>
   <font face=symbol>å</font>_u  <font face=symbol>Î</font>  L_v \exclu(u) 
</td>
<td style="border-right:1 solid black;border-top:1 solid black;border-bottom:1 solid black;">&nbsp;
</td>
<td>
   +  <font face=symbol>Î</font> clu(w) - \exclu(w) 
</td>
<td style="border-right:1 solid black;border-top:1 solid black;border-bottom:1 solid black;">&nbsp;
</td>
<td>
   <td>
   = <br>

  =& \max  <font face=symbol>å</font>_u  <font face=symbol>Î</font>  L_v \exclu(u), &nbsp;&nbsp;&nbsp; <font face=symbol>å</font>_u  <font face=symbol>Î</font>  L_v \exclu(u) +
  \max_w  <font face=symbol>Î</font>  L_v 
</td>
<td style="border-left:1 solid black;border-top:1 solid black;border-bottom:1 solid black;">&nbsp;
</td>
<td>
    <font face=symbol>Î</font> clu(w) - \exclu(w) 
</td>
<td style="border-right:1 solid black;border-top:1 solid black;border-bottom:1 solid black;">&nbsp;
</td>
<td>
   <td>
   = <br>

  =& \max   <font face=symbol>Î</font> clu(v) - 1, &nbsp;&nbsp;&nbsp;  <font face=symbol>Î</font> clu(v) - 1 + \max_w  <font face=symbol>Î</font>  L_v 
</td>
<td style="border-left:1 solid black;border-top:1 solid black;border-bottom:1 solid black;">&nbsp;
</td>
<td>
    <font face=symbol>Î</font> clu(w) - \exclu(w) 
</td>
<td style="border-right:1 solid black;border-top:1 solid black;border-bottom:1 solid black;">&nbsp;
</td>
<td>
  
  <td>
   = <br>

  =& \max  0, &nbsp;&nbsp;&nbsp; \max_w  <font face=symbol>Î</font>  L_v 
</td>
<td style="border-left:1 solid black;border-top:1 solid black;border-bottom:1 solid black;">&nbsp;
</td>
<td>
    <font face=symbol>Î</font> clu(w) - \exclu(w) 
</td>
<td style="border-right:1 solid black;border-top:1 solid black;border-bottom:1 solid black;">&nbsp;
</td>
<td>
   <td>
   +
   <font face=symbol>Î</font> clu(v) - 1.
\endalign*
Therefore,

<table cellspacing=0  border=0 align=center>
<tr>
  <td nowrap align="center">
    
  \exclu(v) = \max  0, &nbsp;&nbsp;&nbsp; \max<sub>w  <font face=symbol>Î</font>  L<sub>v</sub></sub> 
  </td>
  <td style="border-left:1 solid black;border-top:1 solid black;border-bottom:1 solid black;">&nbsp;
  </td>
  <td>
      <font face=symbol>Î</font> clu(w) <font face=symbol>-</font> \exclu(w) 
  </td>
  <td style="border-right:1 solid black;border-top:1 solid black;border-bottom:1 solid black;">&nbsp;
  </td>
  <td>
     <td>
     +
   <font face=symbol>Î</font> clu(v) <font face=symbol>-</font> 1.
<a name="eq2">&nbsp;&nbsp;&nbsp;&nbsp;<font color=blue>(2)</font>
  </td>
</tr>
</table>

To sum it up, for any vertex v:

<table cellspacing=0  border=0 align=center>
<tr>
  <td nowrap align="center">
    
  \exclu(v) =
  \begincases
    0, & \textif  v \text is a leaf; <br>
    
    \max  0, &nbsp;&nbsp;&nbsp; \maxlimits<sub>w  <font face=symbol>Î</font>  L<sub>v</sub></sub> 
  </td>
  <td style="border-left:1 solid black;border-top:1 solid black;border-bottom:1 solid black;">&nbsp;
  </td>
  <td>
      <font face=symbol>Î</font> clu(w) <font face=symbol>-</font> \exclu(w) 
  </td>
  <td style="border-right:1 solid black;border-top:1 solid black;border-bottom:1 solid black;">&nbsp;
  </td>
  <td>
     <td>
     +
     <font face=symbol>Î</font> clu(v) <font face=symbol>-</font> 1 & \textotherwise <br>
    
  \endcases
<a name="eq3">&nbsp;&nbsp;&nbsp;&nbsp;<font color=blue>(3)</font>
  </td>
</tr>
</table>

and

<table cellspacing=0  border=0 align=center>
<tr>
  <td nowrap align="center">
    
   <font face=symbol>Î</font> clu(v) =
  \begincases
    1, & \textif  v \text is a leaf; <br>
    
    1 + 
  </td>
  <td nowrap align=center>
    <!--UB--><font face=symbol>å</font>limits<sub>u  <font face=symbol>Î</font>  L<sub>v</sub></sub> \exclu(u) & \textotherwise
  \endcases
<a name="eq4">&nbsp;&nbsp;&nbsp;&nbsp;<font color=blue>(4)</font>
  </td>
</tr>
</table>

hold. Using those recurrences, we can iterate over all connected components of the graph,
do a depth-first search
on them and calculate the values of  <font face=symbol>Î</font> clu(v) and \exclu(v) for all vertices v.
Finally, we can output N <font face=symbol>-</font> 
</td>
<td style="border-left:1 solid black;border-top:1 solid black;border-bottom:1 solid black;">&nbsp;
</td>
<td>
   <font face=symbol>å</font> \exclu(r) 
</td>
<td style="border-right:1 solid black;border-top:1 solid black;border-bottom:1 solid black;">&nbsp;
</td>
<td>
   over all roots r. Each vertex
needs to be traversed only once, which gives a runtime of \mathcalO(N).

<h2>Subtask 4</h2>
The subtask is solved similarly to subtask 3. We will process each connected component
separately. If the cycle of the current component consists of just one character, we will
process it the same way as in subtask 3. If the cycle is longer, we pick one arbitrary
character. In the optimal solution, that character either is in a relationship with the
person they love, or isn<font face=symbol>¢</font>t. In both cases we can eliminate some arcs from the component so that
the component becomes a forest of directed trees. Using the solution from subtask 4, we
can calculate the number of love arrows needed in both situations and pick the better one.
This solves the subtask in \mathcalO(N). <font face=symbol>©</font>

<h1>Martian DNA</h1>

<h2>Subtask 1</h2>
Let s = s<sub>1</sub> s<sub>2</sub> <font face=symbol>¼</font> s<sub>N</sub> denote the DNA string.
Given a substring t=s<sub>i</sub> s<sub>i+1</sub><font face=symbol>¼</font> s<sub>j</sub>, we can check in time \mathcalO(N&#183; R) whether it contains sufficiently many of all nucleobases, by simply looping over each required nucleobase and counting how many occurrences there are of that nucleobase in the substring. Suppose we have a function \textttHasEnough(t) which returns \texttttrue if the substring t contains sufficiently many of all nucleobases. Then we can find the optimal substring by looping over all substrings (there are \binomN+12=\mathcalO(N<sup>2</sup>) of them) and picking the shortest substring t such that \textttHasEnough(t) = \texttttrue. The time complexity of this algorithm is \mathcalO(N<sup>3</sup> R).
<h2>Subtask 2</h2>
If we do some precomputations we can actually compute the function \textttHasEnough(t) in time \mathcalO(R). The idea is to use \emphprefix sums, which means that we start by computing, for each required nucleobase, how many times that nucleobase occurs in each prefix of the DNA, which allows us to quickly compute how many times that nucleobase occurs in any substring. If we let \textttcount<sub>c</sub>(m) denote the number of times the nucleobase c occurs in the prefix s<sub>1</sub><font face=symbol>¼</font> s<sub>m</sub>, then we can compute how many times c occurs in the substring t=s<sub>i</sub>s<sub>i+1</sub>,<font face=symbol>¼</font>,s<sub>j</sub> as \textttcount<sub>c</sub>(j)<font face=symbol>-</font>\textttcount<sub>c</sub>(i<font face=symbol>-</font>1), which only takes time \mathcalO(1) per type of nucleobase. We can therefore check if we have enough of all required nucleobases in time \mathcalO(R).

The precomputation can be done in time \mathcalO(N R), and then we can use the \mathcalO(R) implementation of \textttHasEnough to test all substrings in time \mathcalO(N<sup>2</sup> R).

<h2>Subtask 3</h2>
The key realization needed to solve subtask 3, where N may be as large as 100000, is that we don<font face=symbol>¢</font>t actually have to check all substrings. Instead, it would be sufficient to know, for each i  <font face=symbol>Î</font>  {1,<font face=symbol>¼</font>,N}, what is the minimum j such that the substring s<sub>i</sub> <font face=symbol>¼</font> s<sub>j</sub> contains sufficiently many of all nucleobases. We can find j using \emphbinary search, because whenever \textttHasEnough(s<sub>i</sub><font face=symbol>¼</font> s<sub>j<font face=symbol>¢</font></sub>) returns \texttttrue then we get an upper bound j  <font face=symbol>£</font>  j<font face=symbol>¢</font>, and whenever \textttHasEnough(s<sub>i</sub> <font face=symbol>¼</font> s<sub>j<font face=symbol>¢</font></sub>) returns \textttfalse we get a lower bound j  <font face=symbol>³</font>  j<font face=symbol>¢</font>. If we also compute \textttHasEnough using prefix sums then the algorithm runs in time \mathcalO(NR + NR \log N) = \mathcalO(NR \log N).
<h2>Subtask 4</h2>
To solve the problem in time \mathcalO(N), we can use an approach based on \emphtwo pointers. At all times we keep track of a substring s<sub><i>l</i></sub> <font face=symbol>¼</font> s<sub>r</sub>. If \textttHasEnough(s<sub><i>l</i></sub> <font face=symbol>¼</font> s<sub>r</sub>) = \textttfalse then the substring is too small, so we make it bigger by setting r  <font face=symbol>³</font> ts r+1. If, on the other hand, \textttHasEnough(s<sub><i>l</i></sub> <font face=symbol>¼</font> s<sub>r</sub>) = \texttttrue then we might be able to make the substring smaller, so we set <i>l</i>  <font face=symbol>³</font> ts <i>l</i> + 1. This way we only have to check \mathcalO(N) different substrings. 

The problem is that precomputing all the prefix sums needed for \textttHasEnough takes time <font face=symbol>Q</font>(NR), which is too slow. However, we can exploit the fact that when we increment <i>l</i> or r, the substring s<sub><i>l</i></sub> <font face=symbol>¼</font> s<sub>r</sub> doesn<font face=symbol>¢</font>t change very much, so we can keep track of:
<ol>

<li> How many nucleobases there are of each type in the substring s<sub><i>l</i></sub> <font face=symbol>¼</font> s<sub>r</sub>.

<li> How many of the required nucleobases that have too few occurrences in the substring s<sub><i>l</i></sub> <font face=symbol>¼</font> s<sub>r</sub>.
</ol>
Whenever we increment the left pointer <i>l</i>, we first decrement the number of nucleobases of type s<sub><i>l</i></sub>, and if the number of nucleobases of that type becomes too small we also increment the number of nucleobases with an insufficient number of occurrences.

Similarly, whenever we increment the right pointer r, we first increment the number of nucleobases of type s<sub>r+1</sub>, and if the number of nucleobases of that type becomes exactly the number we need then we also decrement the number of nucleobases with an insufficient number of occurrences.

If we keep track of the number of nucleobases with too few occurrences, then we can implement \textttHasEnough(s<sub><i>l</i></sub> <font face=symbol>¼</font> s<sub>r</sub>) by simply checking if there are \emphno nucleobases with too few occurrences, which is a constant time operation. Hence this algorithm runs in \mathcalO(N).

<h1>Worm Worries</h1>

This problem is really three problems in one, for the cases of one, two and three dimensions.
Most solutions work across any number of dimensions, but to get an optimal number of queries (for testgroups 2, 4 and 6), the three cases required separate solutions.

<ol>

<li> For one dimension, we can first try something like a binary search. Let<font face=symbol>¢</font>s say we have a grid of size N &times; 1 &times; 1. We can reduce the problem to a smaller one as follows: ask for the value of the middle two points, say H[N/2] and H[N/2+1]. If H[N/2]  <font face=symbol>³</font>  H[N/2+1], then we can reduce the problem to finding a local maximum of the first half of the array (including element N/2), otherwise to the second half.

However, this uses 40 queries for N = 1&nbsp;000&nbsp;000, while testgroup 2 requires at most 35. Getting to 35 queries another approach, based on the idea of \emphgolden section search.

Say we want to find a local maximum in the interval [a, b]. If a=b, then we just return a. Otherwise, we might query two points m, m+1, say in the middle of the interval, and recursively find a local maximum in either [a, m] or [m+1, b], depending on which of H[m], H[m+1] is bigger. But we don<font face=symbol>¢</font>t need the queried points m, m+1 to be adjacent: suppose instead that we query two points x, y, x &lt; y. Again, if H[x]  <font face=symbol>³</font>  H[y], we can recurse in [a, y<font face=symbol>-</font>1]; otherwise we recurse in [x+1, b]. But when we recurse in [a, y<font face=symbol>-</font>1], we already have one queried point in the interval, x, so we just need to query one point in the next step. To see why this recursion will indeed produce a local maximum, note that the the point you find in the end will be the best among all the queried points. 

To find the right x, y to start with, we use the golden ratio <font face=symbol>f</font> = (1 + \sqrt 5)/(\sqrt 5 <font face=symbol>-</font> 1)2  <font face=symbol>»</font>  0.618. If we let x = 0.618 a + 0.382 b (rounded to the nearest integer), y = 0.382a + 0.618 b to start with, and recurse in [a, y<font face=symbol>-</font>1], then x  <font face=symbol>»</font>  0.382 a + 0.618(y<font face=symbol>-</font>1), so the points in the middle will always roughly form the same golden ratio.

This solution uses 29  <font face=symbol>»</font>  \log<sub><font face=symbol>f</font></sub> N queries, whereas binary search would use 40  <font face=symbol>»</font>  \log<sub>2</sub> N.


<li> For two dimensions, we can reuse some of the ideas of the binary search from the one-dimension case. Let us ask about the values of a line that cuts the rectangle in two. Consider the maximum of the values, and also query the two values to the left and right of this maximum (assuming the cut is vertical). If they are both less or equal to the maximum value, our point is a valid answer. Otherwise, we can recurse on a side where it increases. Intuitively, if we then continued walking to larger and larger values, we could never again cross the cutting line, because the value we walked to was larger than every value on it. There are some subtleties to this, where we have to make sure to recurse on the side that have the previously found maximal query value if that value is larger than the maximum value on the cutting line -- otherwise, a local maximum that we found in a subrectangle may not be a local maximum of a full rectangle. Correctly implemented, though, this solves subtasks 3 and 4, assuming you alternate vertical and horizontal splits. It can also be generalized to 1 and 3 dimensions, solving subtasks 1 and 5.


<li> One naive idea is to query points at random, and then print the best one, i.e. the one with the highest humidity. Another naive idea is to start from a random point, query adjacent points, and move in the direction of increasing humidity until you find a local maximum.

Neither of these ideas work very well in the worst case, but they can be combined into a solution: First query Q / 2 points at random. Then choose the best one, and move in the direction of increasing humidity until you arrive at a local maximum.

Why does this work? Suppose in the first stage you find a point among the Q / 12 best points. Then as you move to better points, you will need at most Q / 12 steps. For each step, you might need to query 6 points (or 3 on average if you do this cleverly), so you will need  Q / 12  &#183; 6 = Q / 2 queries in the second stage, i.e. Q queries in total. So we succeed if we find a point among the Q / 12 best points.

The probability of not finding one of these points is at most 

<table cellspacing=0  border=0 align=center>
<tr>
  <td nowrap align=center>
    
  </td>
  <td style="border-left:1 solid black;border-top:1 solid black;border-bottom:1 solid black;">&nbsp;
  </td>
  <td>
    1 <font face=symbol>-</font> \frac Q 12NMK
  </td>
  <td style="border-right:1 solid black;border-top:1 solid black;border-bottom:1 solid black;">&nbsp;
  </td>
  <td valign=top>
    <sup>Q/2</sup>
  </td>
  <td nowrap align=center>
      <font face=symbol>»</font>  exp 
  </td>
  <td style="border-left:1 solid black;border-top:1 solid black;border-bottom:1 solid black;">&nbsp;
  </td>
  <td>
     <font face=symbol>-</font>  \frac Q 12NMK \frac Q 2 
  </td>
  <td style="border-right:1 solid black;border-top:1 solid black;border-bottom:1 solid black;">&nbsp;
  </td>
  <td>
     = exp 
  </td>
  <td style="border-left:1 solid black;border-top:1 solid black;border-bottom:1 solid black;">&nbsp;
  </td>
  <td>
    <font face=symbol>-</font> \frac Q<sup>2</sup>24 NMK 
  </td>
  <td style="border-right:1 solid black;border-top:1 solid black;border-bottom:1 solid black;">&nbsp;
  </td>
  <td>
     .
  </td>
</tr>
</table>

For group 6, this gives a probability of failure less than 1 in 1800. This solution will also solve group 1, 3, and 5.
</ol>

Fun facts about this problem:

<ul>

<li> The grader for this task was 900 lines long, and implemented 14 different strategies for (on-demand per query) test data generation. This included random test data, space-filling curves, spirals, random line segment paths with slopes leading up to them, and fun 1d functions like randomly rescaled <font face=symbol>Ö</font><span style="border-top:1 solid black;">x</span> and sawtooth functions.

<li> We had vague plans on extending the task to 4d, but scrapped them. If anyone wants code for random space-filling curves in 4d, just ask.

<li> Apparently this problem has been fairly well studied by computer scientists, with regards to upper and lower bounds. See for instance:
<ul>

<li> \hrefhttps://arxiv.org/abs/quant-ph/0504085https://arxiv.org/abs/quant-ph/0504085

<li> \hrefhttps://epubs.siam.org/doi/pdf/10.1137/S0097539704447237https://epubs.siam.org/doi/pdf/10.1137/S0097539704447237
</ul>
</ul>

\enddocument</body>
</html>
